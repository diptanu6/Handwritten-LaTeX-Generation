# Handwritten-LaTeX-Generation


**Handwritten-LaTeX-Generation** is a deep learningâ€“based project that converts *handwritten mathematical expressions* into structured **LaTeX code**.
It combines **vision-language transformer models** with fine-tuning on the **Im2LaTeX-230K dataset** to achieve accurate symbol recognition and expression formatting.

---

## ğŸš€ Project Overview

Mathematical expression recognition requires understanding both **visual structure** and **symbolic semantics**.
This project integrates:

* ğŸ§© **Microsoft TrOCR** for handwritten text recognition
* ğŸ§  **Vision-Language Models (Qwen2-VL / LLaMA-3.2)** for multimodal sequence learning
* ğŸ“œ **Transformer-based LaTeX generator** trained on **Im2LaTeX-230K**

The system, **Handwritten-LaTeX-Generation**, can interpret handwritten equations and generate their equivalent LaTeX markup.

---

## ğŸ§° Tech Stack

* **Language:** Python
* **Frameworks:** PyTorch, Hugging Face Transformers
* **Libraries:** OpenCV, NumPy, Matplotlib, scikit-learn
* **Environment:** Google Colab
* **Base Models:** TrOCR, Qwen2-VL, LLaMA-3.2, ViT Encoder

---

## ğŸ“Š Dataset: Im2LaTeX-230K

The **Im2LaTeX-230K** dataset is a large-scale collection of rendered mathematical expressions with their LaTeX source.

### ğŸ“ Dataset Structure

| Component   | Description                                 |
| ----------- | ------------------------------------------- |
| **Images**  | Rendered mathematical formulas (PNG format) |
| **Labels**  | Corresponding LaTeX strings                 |
| **Samples** | 230,000+ imageâ€“LaTeX pairs                  |
| **Split**   | Train / Validation / Test                   |
| **Format**  | `<image_path> \t <LaTeX_code>`              |

### ğŸ” Example

```
img_0000123.png    \frac{a+b}{c+d}
img_0000456.png    \int_{0}^{\infty} e^{-x^2} dx
```

### ğŸ§ª Why Im2LaTeX-230K?

* Covers diverse mathematical notations (integrals, fractions, matrices, limits, etc.)
* Provides clean LaTeX annotations suitable for sequence-to-sequence training
* Compatible with Transformer-based models for multimodal learning

---

## ğŸ§© Model Architecture

1. **Encoder:** Vision Transformer (ViT) extracts spatial features from handwritten input images.
2. **Decoder:** Transformer-based LaTeX generator produces tokenized LaTeX sequences.
3. **Loss Function:** Cross-Entropy with teacher forcing.
4. **Metrics:**

   * Exact Match Accuracy
   * Expression Recognition Rate (ERR)
   * BLEU Score
   * Edit Distance

---

## ğŸ§  Training Workflow

1. Preprocess images and tokenize LaTeX expressions
2. Load pretrained encoder (TrOCR / Qwen2-VL)
3. Fine-tune model on Im2LaTeX-230K dataset
4. Validate and evaluate with BLEU, ERR, and Exact Match
5. Generate LaTeX predictions and visualize output

---

## âš™ï¸ Usage

```bash
# Clone the repository
git clone https://github.com/yourusername/Handwritten-LaTeX-Generation.git
cd Handwritten-LaTeX-Generation

# Install dependencies
pip install -r requirements.txt

# Run the notebook
jupyter notebook hwrite2latex.ipynb
```

---

## ğŸ“ˆ Results & Discussion

* The model achieves high recognition accuracy on structured handwritten equations.
* Fine-tuning with **TrOCR + Qwen2-VL** improves semantic consistency and spacing in generated LaTeX.
* Evaluation shows balanced performance across both clean and noisy inputs.

---

## ğŸ“š References

* *Deng et al., â€œIm2LaTeX: Translating Images to Markup,â€ arXiv:1609.04938 (2016)*
* *Microsoft TrOCR: Transformer-based OCR*
* *Qwen2-VL and LLaMA-3.2 Vision-Language models (2024â€“2025)*
* *CROHME: Competition on Recognition of Online Handwritten Mathematical Expressions*

---

## ğŸ§‘â€ğŸ’» Author

**Diptanu Biswas**
Final-Year BTMT (Computational Mathematics), NIT Agartala
ğŸ“§ [diptanubiswas@email.com](mailto:diptanubiswas@email.com)
ğŸ’¼ [LinkedIn](https://linkedin.com/in/diptanubiswas)â€ƒğŸ™ [GitHub](https://github.com/yourusername)

---

## ğŸ Future Work

* Fine-tuning with CROHME dataset for handwritten variations
* Integration of live **LaTeX rendering** interface
* Deployment via **FastAPI + Streamlit** for real-time usage

---

**â­ If this project helps your research or work, please star the repo and share feedback!**
